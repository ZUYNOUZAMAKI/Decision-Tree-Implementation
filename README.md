# Decision-Tree-Implementation

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: ZUHAYR YASSER NONGBRI

*INTERN ID*: CTIS3566

*DOMAIN*: MACHINE LEARNING

*DURATION*: 4 WEEKS

*MENTOR*: NEELA SANTOSH

*DESCRIPTION*: ğŸ“Œ Project Overview

This project demonstrates the implementation, visualization, and analysis of a Decision Tree Classifier using the scikit-learn library. A synthetically generated, highly separable dataset is used to train the model, allowing it to achieve high classification accuracy (97â€“99%) while maintaining strong interpretability.

The project is designed to help understand how decision trees make decisions based on feature splits and how model performance can be evaluated using standard metrics.

ğŸ§  Objective

To build a Decision Tree classification model

To visualize the learned decision rules

To evaluate the model using accuracy and a confusion matrix

To understand feature importance and model behavior

ğŸ“Š Dataset

Generated using make_classification() from scikit-learn

1200 samples with 6 features

5 informative features and no redundant features

High class separability for reliable performance

Binary classification problem

âš™ï¸ Model Details

Algorithm: Decision Tree Classifier

Criterion: Gini Impurity

Maximum Depth: 4

Trainâ€“Test Split: 75% / 25%

ğŸ“ˆ Results

Accuracy: ~98%

Minimal misclassification as shown in the confusion matrix

Several leaf nodes achieve zero impurity, indicating perfect classification in those regions

Clear and interpretable decision boundaries

ğŸ“‰ Visualizations

Decision Tree structure showing feature splits, impurity, and class predictions

Confusion Matrix illustrating classification performance

Feature importance scores indicating influential features

ğŸ› ï¸ Technologies Used

Python

Scikit-learn

NumPy

Matplotlib

Google Colab

ğŸš€ How to Run

Open the notebook in Google Colab

Run all cells sequentially

View model accuracy, decision tree visualization, and confusion matrix

ğŸ“š Learning Outcomes

Understanding decision tree construction and splitting criteria

Interpreting tree-based model decisions

Evaluating classification models effectively

Visualizing machine learning models for better explainability
